# slimSAC - simple, minimal and flexible Deep RL with SAC.

![python](https://img.shields.io/badge/python-3.10%20%7C%203.11%20%7C%203.12-blue)
![jax_badge][jax_badge_link]
![Static Badge](https://img.shields.io/badge/lines%20of%20code-3060-green)
<a href="https://github.com/psf/black"><img alt="Code style: black" src="https://img.shields.io/badge/code%20style-black-000000.svg"></a>
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

**`slimSAC`** provides a concise and customizable implementation of the SAC algorithm in Reinforcement Learning‚õ≥ for MuJoCo environments. 
It enables to quickly code and run proof-of-concept type of experiments in off-policy Deep RL settings.

### üöÄ Key advantages
‚úÖ Easy to read - clears the clutter with minimal lines of code üßπ\
‚úÖ Easy to experiment - flexible to play with algorithms and environments üìä\
‚úÖ Fast to run - jax accleration, support for GPU and multiprocessing ‚ö°

<p align="center">
  <img width=48% src="images/lunar_lander.gif">
  <img width=48% src="images/car_on_hill.gif">
</p>


Let's dive in!

## User installation

We recommend python 3.11.5
In the folder where the code is, create a Python virtual environment, activate it, update pip and install the package and its dependencies in editable mode:
CPU installation:
```bash
python3.11 -m venv env_cpu 
source env_cpu/bin/activate
pip install --upgrade pip setuptools wheel
pip install -e .[dev]
```
GPU installation:
```bash
python3.11 -m venv env_gpu 
source env_gpu/bin/activate
pip install --upgrade pip setuptools wheel
pip install -e .[dev,gpu]
```
To verify the installation, run the tests as:```pytest```

## Running experiments
`slimSAC` provides support for [MuJoCo](https://gymnasium.farama.org/environments/mujoco/#) environments. 
### Training

To train a SAC agent on a MuJoCo environment on your local system, run (provide the `--gpu` flag if you want to use GPU):\
`
python3 -m experiments.mujoco.sac --seed "{SEED}" -en "{experiment_name}" -dw
`

`
Example: python3 -m experiments.mujoco.sac --seed "0" -en "test_Hopper" -dw
`

The full args-list is:\
`-en {experiment_name}           # REQUIRED: experiment name (str)`\
`-s  {seed}                      # REQUIRED: random seed (int)`\
`-dw                             # OPTIONAL: disable wandb (flag)`\
`--replay_buffer_capacity {int}  # OPTIONAL: replay‚Äêbuffer size (default: 1_000_000)
`\
`--batch_size {int}              # OPTIONAL: batch size (default: 256)`\
`--learning_starts {int}         # OPTIONAL: samples before training (default: 5000)`\
`--update_horizon {int}          # OPTIONAL: n-step TD horizon (default: 1)` \
`--gamma {float}                 # OPTIONAL: discount factor (default: 0.99)`\
`--learning_rate {float}         # OPTIONAL: optimiser LR (default: 1e-3)`\
`--horizon {int}                 # OPTIONAL: truncation horizon (default: 1000)`\
`--n_samples {int}               # OPTIONAL: total samples (default: 1_000_000)`\
`--update_to_data {float}        # OPTIONAL: updates per new sample (default: 1)`\
`--features_qf {int [int ‚Ä¶]}     # OPTIONAL: Q-net layer sizes (default: 256 256)`\
`--features_pi {int [int ‚Ä¶]}     # OPTIONAL: policy layer sizes (default: 256 256)`\
`--tau {float}                   # OPTIONAL: target-update œÑ (default: 5e-3)`\




It trains a SAC agent with 2 hidden layers of size 256 (actor and critic), for a single seed for 100 epochs. 

- Outputs and logs can be seen in wandb.
- The models and results are stored in `experiments/mujoco/exp_output/{experiment_name}/dqn` folder

To train on cluster:\
`
bash launch_job/mujoco/local_sac.sh  -en {experiment_name}  --first_seed 0 --last_seed 0 --features 100 100 --learning_rate 3e-4 --n_epochs 100
`
Example:\
`
bash launch_job/mujoco/local_sac.sh -en sac_HalfCheetah --first_seed 0 --last_seed 9
`



<!-- ## Collaboration
To report bugs or suggest improvements, use the [issues page](https://github.com/theovincent/slimSAC/issues) of this repository. -->

## License
This project is licensed under the MIT License. See the [LICENSE](https://github.com/theovincent/slimRL/blob/main/LICENSE) file for details.



[jax_badge_link]: https://img.shields.io/badge/JAX-Accelerated-9cf.svg?style=flat-square&logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAC0AAAAaCAYAAAAjZdWPAAAIx0lEQVR42rWWBVQbWxOAkefur%2B7u3les7u7F3ZIQ3N2tbng8aXFC0uAuKf2hmlJ3AapIgobMv7t0w%2Ba50JzzJdlhlvNldubeq%2FY%2BXrTS1z%2B6sttrKfQOOY4ns13ecFImb47pVvIkukNe4y3Junr1kSZ%2Bb3Na248tx7rKiHlPo6Ryse%2F11NKQuk%2FV3tfL52yHtXm8TGYS1wk4J093wrPQPngRJH9HH1x2fAjMhcIeIaXKQCmd2Gn7IqSvG83BueT0CMkTyESUqm3vRRggTdOBIb1HFDaNl8Gdg91AFGkO7QXe8gJInpoDjEXC9gbhtWH3rjZ%2F9yK6t42Y9zyiC1iLhZA8JQe4eqKXklrJF0MqfPv2bc2wzPZjpnEyMEVlEZCKQzYCJhE8QEtIL1RaXEVFEGmEaTn96VuLDzWflLFbgvqUec3BPVBmeBnNwUiakq1I31UcPaTSR8%2B1LnditsscaB2A48K6D9SoZDD2O6bELvA0JGhl4zIYZzcWtD%2BMfdvdHNsDOHciXwBPN18lj7sy79qQCTNK3nxBZXakqbZFO2jHskA7zBs%2BJhmDmr0RhoadIZjYxKIVHpCZngPMZUKoQKrfEoz1PfZZdKAe2CvP4XnYE8k2LLMdMumwrLaNlomyVqK0UdwN%2BD7AAz73dYBpPg6gPiCN8TXFHCI2s7AWYesJgTabD%2FS5uXDTuwVaAvvghncTdk1DYGkL0daAs%2BsLiutLrn0%2BRMNXpunC7mgkCpshfbw4OhrUvMkYo%2F0c4XtHS1waY4mlG6To8oG1TKjs78xV5fAkSgqcZSL0GoszfxEAW0fUludRNWlIhGsljzVjctr8rJOkCpskKaDYIlgkVoCmF0kp%2FbW%2FU%2F%2B8QNdXPztbAc4kFxIEmNGwKuI9y5gnBMH%2BakiZxlfGaLP48kyj4qPFkeIPh0Q6lt861zZF%2BgBpDcAxT3gEOjGxMDLQRSn9XaDzPWdOstkEN7uez6jmgLOYilR7NkFwLh%2B4G0SQMnMwRp8jaCrwEs8eEmFW2VsNd07HQdP4TgWxNTYcFcKHPhRYFOWLfJJBE5FefTQsWiKRaOw6FBr6ob1RP3EoqdbHsWFDwAYvaVI28DaK8AHs51tU%2BA3Z8CUXvZ1jnSR7SRS2SnwKw4O8B1rCjwrjgt1gSrjXnWhBxjD0Hidm4vfj3e3riUP5PcUCYlZxsYFDK41XnLlUANwVeeILFde%2BGKLhk3zgyZNeQjcSHPMEKSyPPQKfIcKfIqCf8yN95MGZZ1bj98WJ%2BOorQzxsPqcYdX9orw8420jBQNfJVVmTOStEUqFz5dq%2F2tHUY3LbjMh0qYxCwCGxRep8%2FK4ZnldzuUkjJLPDhkzrUFBoHYBjk3odtNMYoJVGx9BG2JTNVehksmRaGUwMbYQITk3Xw9gOxbNoGaA8RWjwuQdsXdGvpdty7Su2%2Fqn0qbzWsXYp0nqVpet0O6zzugva1MZHUdwHk9G8aH7raHua9AIxzzjxDaw4w4cpvEQlM84kwdI0hkpsPpcOtUeaVM8hQT2Qtb4ckUbaYw4fXzGAqSVEd8CGpqamj%2F9Q2pPX7miW0NlHlDE81AxLSI2wyK6xf6vfrcgEwb0PAtPaHM1%2BNXzGXAlMRcUIrMpiE6%2Bxv0cyxSrC6FmjzvkWJE3OxpY%2BzmpsANFBxK6RuIJvXe7bUHNd4zfCwvPPh9unSO%2BbIL2JY53QDqvdbsEi2%2BuwEEHPsfFRdOqjHcjTaCLmWdBewtKzHEwKZynSGgtTaSqx7dwMeBLRhR1LETDhu76vgTFfMLi8zc8F7hoRPpAYjAWCp0Jy5dzfSEfltGU6M9oVCIATnPoGKImDUJNfK0JS37QTc9yY7eDKzIX5wR4wN8RTya4jETAvZDCmFeEPwhNXoOlQt5JnRzqhxLZBpY%2BT5mZD3M4MfLnDW6U%2Fy6jkaDXtysDm8vjxY%2FXYnLebkelXaQtSSge2IhBj9kjMLF41duDUNRiDLHEzfaigsoxRzWG6B0kZ2%2BoRA3dD2lRa44ZrM%2FBW5ANziVApGLaKCYucXOCEdhoew5Y%2Btu65VwJqxUC1j4lav6UwpIJfnRswQUIMawPSr2LGp6WwLDYJ2TwoMNbf6Tdni%2FEuNvAdEvuUZAwFERLVXg7pg9xt1djZgqV7DmuHFGQI9Sje2A9dR%2FFDd0osztIRYnln1hdW1dff%2B1gtNLN1u0ViZy9BBlu%2BzBNUK%2BrIaP9Nla2TG%2BETHwq2kXzmS4XxXmSVan9KMYUprrbgFJqCndyIw9fgdh8dMvzIiW0sngbxoGlniN6LffruTEIGE9khBw5T2FDmWlTYqrnEPa7aF%2FYYcPYiUE48Ul5jhP82tj%2FiESyJilCeLdQRpod6No3xJNNHeZBpOBsiAzm5rg2dBZYSyH9Hob0EOFqqh3vWOuHbFR5eXcORp4OzwTUA4rUzVfJ4q%2FIa1GzCrzjOMxQr5uqLAWUOwgaHOphrgF0r2epYh%2FytdjBmUAurfM6CxruT3Ee%2BDv2%2FHAwK4RUIPskqK%2Fw4%2FR1F1bWfHjbNiXcYl6RwGJcMOMdXZaEVxCutSN1SGLMx3JfzCdlU8THZFFC%2BJJuB2964wSGdmq3I2FEcpWYVfHm4jmXd%2BRn7agFn9oFaWGYhBmJs5v5a0LZUjc3Sr4Ep%2FmFYlX8OdLlFYidM%2B731v7Ly4lfu85l3SSMTAcd5Bg2Sl%2FIHBm3RuacVx%2BrHpFcWjxztavOcOBcTnUhwekkGlsfWEt2%2FkHflB7WqKomGvs9F62l7a%2BRKQQQtRBD9VIlZiLEfRBRfQEmDb32cFQcSjznUP3um%2FkcbV%2BjmNEvqhOQuonjoQh7QF%2BbK811rduN5G6ICLD%2BnmPbi0ur2hrDLKhQYiwRdQrvKjcp%2F%2BL%2BnTz%2Fa4FgvmakvluPMMxbL15Dq5MTYAhOxXM%2FmvEpsoWmtfP9RxnkAIAr%2F5pVxqPxH93msKodRSXIct2l0OU0%2FL4eY506L%2B3GyJ6UMEZfjjCDbysNcWWmFweJP0Jz%2FA0g2gk80pGkYAAAAAElFTkSuQmCC

